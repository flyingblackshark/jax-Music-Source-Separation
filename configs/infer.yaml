inference:
  batch_size: 8
  chunk_size: 960000
  num_overlap: 4
model:
  type: "bs_roformer"
  attention: "tokamax_attention"
  flash_min_seq_len: 2048
